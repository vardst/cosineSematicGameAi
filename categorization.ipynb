{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import tiktoken\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "CHAT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "openai.api_key = os.environ.get('api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_managers = pd.read_csv('managers.csv')\n",
    "df_managers = df_managers.set_index(['title','heading'])\n",
    "\n",
    "df_state = pd.read_csv('state.csv')\n",
    "df_state = df_state.set_index(['title','heading'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings part\n",
    "\n",
    "\n",
    "def get_embedding(text: str, model: str=EMBEDDING_MODEL) -> list[float]:\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
    "    return {\n",
    "        idx: get_embedding(r.content) for idx, r in df.iterrows()\n",
    "    }\n",
    "    \n",
    "def load_embeddings(fname: str) -> dict[tuple[str, str], list[float]]:\n",
    "    df = pd.read_csv(fname, header=0, encoding='utf-8')\n",
    "    df = df.set_index(['title','heading'])\n",
    "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "    return {\n",
    "           (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "    }\n",
    "\n",
    "def get_usage(text: str, model: str = EMBEDDING_MODEL)->int:\n",
    "    result = openai.Embedding.create(\n",
    "        model=model,\n",
    "        imput = text\n",
    "    )\n",
    "    return result[\"usage\"][\"total_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers_embeddings = compute_doc_embeddings(df_managers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_embedding = compute_doc_embeddings(df_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Square Sam', 'unlock level = 45') : [-0.00020701090397778898, -0.008801721036434174, 0.00948029663413763, -0.02485036663711071, -0.016799692064523697]... (1536 entries)\n",
      "('mine areas', 8) : [-0.01969183050096035, -0.01719668135046959, -0.004136134870350361, -0.026822851970791817, -0.02761676348745823]... (1536 entries)\n"
     ]
    }
   ],
   "source": [
    "#show embeddings\n",
    "\n",
    "example_entry = list(managers_embeddings.items())[-1]\n",
    "print(f\"{example_entry[0]} : {example_entry[1][:5]}... ({len(example_entry[1])} entries)\")\n",
    "example_entry = list(state_embedding.items())[-1]\n",
    "print(f\"{example_entry[0]} : {example_entry[1][:5]}... ({len(example_entry[1])} entries)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector similarity and user prompt embedding \n",
    "\n",
    "\n",
    "def vector_similarity(x: list[float],y: list[float])->float:\n",
    "    return np.dot(np.array(x),np.array(y))\n",
    "\n",
    "def order_document_selections_by_querry_similarity(query:str , contexts: dict[(str,str),np.array])->list[(float,(str, str))]:\n",
    "    query_embedding = get_embedding(query)\n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding),doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ],reverse = True)\n",
    "    return document_similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manager(prompt)-> list[str,float]:\n",
    "    manager_guess = order_document_selections_by_querry_similarity(prompt,managers_embeddings)[:1][0][1][0]\n",
    "    manager_chance = order_document_selections_by_querry_similarity(prompt,managers_embeddings)[:1][0][0]*100\n",
    "    return [manager_guess,manager_chance]\n",
    "\n",
    "def get_second_manager(prompt)-> list[str,float]:\n",
    "    manager_guess = order_document_selections_by_querry_similarity(prompt,managers_embeddings)[:2][1][1][0]\n",
    "    manager_chance = order_document_selections_by_querry_similarity(prompt,managers_embeddings)[:2][1][0]*100\n",
    "    return [manager_guess,manager_chance]\n",
    "    \n",
    "    manager_guess = order_document_selections_by_querry_similarity(prompt,managers_embeddings)[:1][0][1][0]\n",
    "    manager_chance = order_document_selections_by_querry_similarity(prompt,managers_embeddings)[:1][0][0]*100\n",
    "\n",
    "    state_guess = order_document_selections_by_querry_similarity(prompt,state_embedding)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LillyPI', 82.35284145030951]\n",
      "['Timmy', 81.91692214070527]\n"
     ]
    }
   ],
   "source": [
    "print(get_manager(\"Who is Timmy's Crush ?\"))\n",
    "print(get_second_manager(\"Who is Timmy's Crush ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"prompt\",'r',encoding='utf-8') as f:\n",
    "    prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_messages(messages,role,content):\n",
    "    messages.append({\"role\":role,\"content\":content})\n",
    "    return messages\n",
    "\n",
    "def get_response_messages(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model = CHAT_MODEL,\n",
    "    messages=messages\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt,}\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_df(text,df):\n",
    "    content = df.loc[f'{text}',\"content\"]\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is timmy ? \n",
      "As mentioned earlier, Timmy is the only human manager in the game who was raised by robot parents. He helps boost your production in Idle Humans. If you have any other questions, feel free to ask!\n",
      "Who is the manager that can boost all the floors ?\n",
      "The manager who can boost all of your floors at once is called the \"Barking Dog\" manager. This manager can be unlocked at level 21.\n",
      "When will the manager be ulocked who can boost the bar \n",
      "The manager that can boost your bar revenue can be unlocked at level 23. Keep playing, completing quests and leveling up to unlock this manager and many more!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     querry \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m()\n\u001b[0;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(querry)\n\u001b[0;32m      4\u001b[0m     guessed_manager \u001b[39m=\u001b[39m get_manager(querry)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mf:\\python\\audio\\Lib\\site-packages\\ipykernel\\kernelbase.py:1182\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1180\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1181\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1182\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[0;32m   1183\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[0;32m   1184\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1185\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1186\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1187\u001b[0m )\n",
      "File \u001b[1;32mf:\\python\\audio\\Lib\\site-packages\\ipykernel\\kernelbase.py:1225\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1222\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1223\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1225\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m   1226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1227\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    querry = input()\n",
    "    print(querry)\n",
    "    guessed_manager = get_manager(querry)[0]\n",
    "    get_info = get_text_from_df(guessed_manager,df_managers)\n",
    "    messages = update_messages(messages=messages,role = \"user\",content = querry)\n",
    "    messages = update_messages(messages=messages, role=\"system\" , content=f\"{get_info}\")\n",
    "    model_response = get_response_messages(messages)\n",
    "    print(model_response)\n",
    "    messages = update_messages(messages=messages,role = \"assistant\", content=model_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
